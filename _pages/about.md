---
layout: about
title: about
permalink: /
subtitle: PhD Student, MIT CSAIL / EECS

profile:
  align: right
  image: shihlun.JPG
  image_cicular: false # crops the image to make it circular

cv_pdf: CV_Shih-Lun_Wu_Sep25.pdf
news: false  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
education: false
---
Hi, there! I'm Shih-Lun. I am a Ph.D. student in [CSAIL](https://www.csail.mit.edu) & [EECS](https://www.eecs.mit.edu) at [Massachusetts Institute of Technology (MIT)](https://www.mit.edu). I am fortunate to be advised by Prof. [Anna Huang](https://czhuang.github.io), and we strive to push the frontiers of <b>music generation & interactions</b>, <b>controllable generative models</b>, and <b>preference alignment/tuning</b>. Recently, we built MIDI-LLM (with [live demo](https://midi-llm-demo.vercel.app)!) by adapting Llama LLM for text-to-MIDI music generation.

I graduated in 2024 with a [M.Sc. in Language Technologies](https://lti.cs.cmu.edu/mlt/) from CMU's [Language Technologies Institute](https://www.lti.cs.cmu.edu/), [School of Computer Science](https://www.cs.cmu.edu/), where I was advised by Prof. [Shinji Watanabe](https://sites.google.com/view/shinjiwatanabe) and Prof. [Chris Donahue](https://chrisdonahue.com/). I worked on <b>controllable music generation</b>, <b>audio captioning</b>, and <b>spoken language understanding</b>. I was also a two-time research scientist intern at [Adobe Research](https://research.adobe.com/) (mentor: Dr. [Nick Bryan](https://ccrma.stanford.edu/~njb/)), where we built [Stemphonic](https://stemphonic-demo.vercel.app) (2025) and [Music ControlNet](https://musiccontrolnet.github.io/web/) (2023).

Prior to joining CMU, I received my B.Sc. degree (in Computer Science) from [National Taiwan University](https://www.ntu.edu.tw/english). Also, I've been with two vibrant Taiwanese AI R&D teams: [Asus AICS Center](https://aics.asus.com/home/), and [Taiwan AI Labs](https://ailabs.tw/), working as a software dev intern first, and later as a research engineer.

My undergraduate research focused on <b>symbolic-domain music generation</b>, where I was advised by the wonderful Dr. [Yi-Hsuan Yang](https://affige.github.io/). Feel free to listen to our model's creative works [here](https://slseanwu.github.io/site-musemorphose/), or even [compose](https://github.com/slSeanWU/jazz_transformer) with it! I've also worked with Prof. [Chung-Wei Lin](https://www.csie.ntu.edu.tw/~cwlin/) and Prof. [Eunsuk Kang](https://eskang.github.io/) on <b>formal verification under weakly-hard constraints</b>.
